# “ClarifyChoice-让AI暂停并澄清辅助填报高考志愿”应用软件开发规划

## 1. 产品愿景

| **用户** | **当前最大痛点（按严重程度排序）** | **产品** | **目标** |
| --- | --- | --- | --- |
| 高考考生、家长、老师 | 不知如何借助AI将学生的个人兴趣与职业偏好匹配国家重点投资的大学专业；不知如何借助AI获取理想专业的全国各高校相关专业录取分数的排名信息 | ClarifyChoice | 帮助高考考生、家长和老师借助AI高效匹配学生的个人兴趣、职业偏好与国家重点投资的大学专业，并提供首选专业的全国各高校相关专业录取分数的排名，以便在高考成绩公布后做出明智的志愿填报决策 |

## 2. 用户画像

| **用户** | **特点** | **目标** |
| --- | --- | --- |
| **北京高考考生小吾** | 愿意使用AI帮助自己进行高考志愿填报 | 借助AI高效匹配我的个人兴趣、职业偏好与国家重点投资的大学专业，并提供首选专业在全国各高校的排名，以便在高考成绩公布后做出明智的志愿填报决策 |

## 3. 产品路线图

| **发布日期** | 2025.12.31 | **待定** | **待定** | **待定** |
| --- | --- | --- | --- | --- |
| **版本** | v0.1 根据小吾兴趣推荐国家重点投资专业 | v0.2 获取首选专业的全国高校专业列表 | v0.3 获取首选专业的全国高校近3年录取分数排名 | v0.4 待定 |
| **目标** | 根据小吾的个人兴趣和职业偏好,推荐国家"十四五"规划中的3个重点投资专业 | 待定 | 待定 | 待定 |
| **核心功能** | 生成专业推荐报告:通过AI与小吾交互,分析小吾的兴趣和职业偏好,推荐国家"十四五"规划中的重点投资专业,生成包含3个专业的推荐报告 | 待定 | 待定 | 待定 |
| **验收标准** | 推荐报告中每个专业应包含:核心课程内容、匹配小吾的理由、未来职业方向、就业前景与挑战、国内录取分数排名前5的大学及专业名称、给小吾的建议 | 待定 | 待定 | 待定 |

## 4. 用户旅程

| **1. 梳理自己的基本信息（高考所在地、三门选考科目、擅长科目、兴趣爱好、期望的工作类型）** | **2.阅读阳光高考网上的十四五规划并找出与自己兴趣相关的国家重点投资的大学专业** | **3.将自己感兴趣的3个国家重点投资的大学专业按兴趣度从高到低排序** | **4.针对每个感兴趣的专业上网找出：**核心课程内容、未来职业方向、就业前景与挑战、国内录取分数排名前5的大学及专业名称 |
| --- | --- | --- | --- |
|  | 痛点1：阅读十四五规划很费时间 | 痛点2：感兴趣的专业匹配小吾的理由不够可视化 | 痛点3：上网搜大学专业相关信息很费时间 |

## 5. 用户故事地图

| 1. 打开ClarifyChoice前端界面，看到有高考生基本信息模版的开场白 | **2. 在提示词输入区向AI提供基本信息（高考所在地、三门选考科目、擅长科目、兴趣爱好、期望的工作类型）后启动与AI的聊天** | **3.在RESEARCH模式下小吾澄清AI对专业推荐报告诉求的疑问** | **4.在INNOVATE模式下小吾从AI提供的若干推荐报告内容框架方案中进行选择** | **5.在PLAN模式下小吾浏览AI提供的推荐报告生成任务清单** | **6.在EXECUTE模式下小吾确认AI生成的推荐报告是否合乎自己的诉求并复制保存** | **7.在REVIEW模式下小吾确认AI是否严格按照PLAN模式中生成的任务清单执行了EXECUTE模式** |
| --- | --- | --- | --- | --- | --- | --- |
| 用户故事1：基础对话系统（MVP）；用户故事2: 流式输出体验；用户故事3: 对话历史持久化；用户故事4: 文件上传功能；用户故事5: 知识库RAG集成；用户故事6: LangGraph智能体工作流 |  |  |  |  |  |  |

## 迭代式开发计划及实施清单

### 核心原则
- ✅ 每个迭代完成后可独立运行和使用
- ✅ 每个迭代增加一个完整的用户可感知功能
- ✅ 后续迭代建立在前序迭代基础上
- ✅ 任何时候项目都可以停止并交付当前功能

### 技术栈选型

**前端技术栈**：
- **Vite 6.x** - 极快的开发服务器和构建工具
- **React 19** - 2025年主流版本，支持最新特性
- **TypeScript 5.x** - 类型安全
- **Tailwind CSS 4.x** - 实用优先的CSS框架
- **React Hooks** - 状态管理和副作用处理
- **react-markdown** - Markdown渲染（迭代6）

**后端技术栈**：
- **Python 3.10+** - 编程语言
- **FastAPI** - 现代化高性能Web框架
- **LangChain 1.0** - LLM应用开发框架
- **LangGraph** - 智能体工作流编排（迭代6）
- **SQLAlchemy + SQLite** - 数据持久化（迭代3）
- **ChromaDB** - 向量数据库（迭代5）

**架构特点**：
- 🎯 **两层架构**：前端直接调用FastAPI后端，无中间层
- 🚀 **开发体验**：Vite热更新极快，调试直观
- 📦 **部署简单**：前端可打包成纯静态文件
- 🔧 **易于维护**：架构清晰，职责分离

---

## 迭代1：基础对话系统（MVP）

**功能目标**：用户可以在浏览器中与AI进行简单对话

**用户价值**：验证AI对话的基本可行性

**技术范围**：
- Vite + React 19 前端（TypeScript + Tailwind CSS）
- 基础聊天界面（输入框+消息列表）
- 简单的LangChain后端（直接调用LLM，无知识库）
- 基础API通信（非流式，前端直接调用FastAPI）

**可交付成果**：
- 用户打开浏览器访问localhost:5173（或3000）
- 输入高考相关问题
- AI返回基于通用知识的回答

**不包含**：
- ❌ 流式输出
- ❌ 对话历史保存
- ❌ 文件上传
- ❌ 知识库检索
- ❌ LangGraph工作流

### 用户故事1：基础对话系统（MVP）

```
作为：高考考生小吾
我想：与AI进行简单对话
以便：验证AI对话的基本可行性

验收条件1.1：用户可以与AI对话，验证基本可行性
GIVEN: 用户打开ClarifyChoice前端界面
AND: 用户在提示词输入区向AI提供"暂停并澄清"风格的高考志愿专业推荐提示词
WHEN: 用户点击"发送"按钮
THEN: AI返回基于通用知识的回答且处于RESEARCH模式
```

### 实施清单（29个任务）

**环境准备**
1. 验证macOS和Windows WSL2上Node.js 18+和Python 3.10+已安装
2. 创建项目根目录ClarifyChoice及子目录frontend、backend

**Vite + React前端搭建**
3. 在frontend目录执行npm create vite@latest . -- --template react-ts初始化
4. 安装基础依赖（npm install）和Tailwind CSS（npm install -D tailwindcss postcss autoprefixer && npx tailwindcss init -p）
5. 配置Tailwind CSS（tailwind.config.js和src/index.css）
6. 创建src/pages/ChatPage.tsx作为主聊天页面
7. 创建src/components/chat/MessageList.tsx显示消息列表
8. 创建src/components/chat/MessageInput.tsx处理用户输入
9. 创建简单的Tailwind样式（用户消息右侧、AI消息左侧）

**后端服务搭建**
10. 在backend目录创建Python虚拟环境
11. 安装依赖：langchain、langchain-openai（或其他LLM）、fastapi、uvicorn、python-dotenv
12. 创建backend/main.py实现FastAPI入口
13. 实现POST /chat端点，接收消息并调用LLM返回响应（非流式）
14. 配置CORS中间件允许前端访问
15. 配置LLM（使用环境变量配置API key）

**前后端集成**
16. 在frontend创建src/services/api.ts封装API调用
17. 实现fetch调用backend的FastAPI服务（http://localhost:8000/chat）
18. 在MessageInput组件实现发送消息逻辑
19. 在MessageList组件实现消息显示逻辑
20. 处理错误状态和加载状态

**启动脚本**
21. 编写backend/start.sh启动FastAPI（端口8000）
22. 编写frontend/start.sh启动Vite开发服务器（端口5173或3000）
23. 编写start-all.sh一键启动前后端

**测试验证**
24. 测试前端页面可以访问（http://localhost:5173）
25. 测试发送消息后AI可以回复
26. 测试macOS环境运行
27. 测试Windows WSL2环境运行

**文档**
28. 编写README.md说明迭代1的功能和启动方法
29. 创建todo-iteration-1.md记录任务清单

---

## 迭代2：流式输出体验

**功能目标**：对话时可以看到AI逐字输出回复

**用户价值**：更好的交互体验，减少等待焦虑

**技术范围**：
- 集成Vercel AI SDK的useChat hook
- 实现SSE流式通信
- 配置LangChain的streaming callbacks
- 优化前端消息渲染

**可交付成果**：
- 基于迭代1的所有功能
- AI回复从"等待后一次性显示"变为"实时逐字显示"

**不包含**：
- ❌ 对话历史保存
- ❌ 文件上传
- ❌ 知识库检索

### 用户故事2: 流式输出体验

```
作为：高考考生小吾
我想：在与AI对话时看到AI逐字输出回复
以便：获得更好的交互体验，减少等待焦虑

验收条件2.1：用户可以看到AI回复实时逐字显示
GIVEN: 用户已在ClarifyChoice前端界面中
AND: 用户在提示词输入区输入问题
WHEN: 用户点击"发送"按钮
THEN: AI的回复从"等待后一次性显示"变为"实时逐字显示"
```

### 实施清单（17个任务）

**依赖安装**
30. 在frontend安装流式处理库（如@microsoft/fetch-event-source或原生EventSource）
31. 在backend安装SSE相关依赖（sse-starlette）

**前端流式改造**
32. 创建src/hooks/useStreamingChat.ts自定义hook管理流式状态
33. 实现SSE（Server-Sent Events）客户端连接逻辑
34. 实现逐token追加到消息的逻辑
35. 修改ChatPage使用useStreamingChat hook
36. MessageList实时显示流式更新的消息

**后端流式改造**
37. 修改backend/main.py的/chat端点返回EventSourceResponse
38. 配置LangChain的StreamingStdOutCallbackHandler
39. 实现逐token通过SSE发送到前端
40. 处理流式传输的错误和结束信号

**测试验证**
41. 测试AI回复是否逐字显示
42. 测试长回复的流式效果
43. 测试网络中断时的错误处理
44. 跨平台运行验证

**文档**
45. 更新README.md添加迭代2功能说明
46. 创建todo-iteration-2.md记录任务清单

---

## 迭代3：对话历史持久化

**功能目标**：用户可以保存对话、查看历史对话、继续之前的对话

**用户价值**：不会丢失对话内容，可以随时回顾

**技术范围**：
- SQLite数据库设计和初始化
- 对话历史CRUD接口
- 侧边栏显示历史对话列表
- 新建对话/切换对话功能

**可交付成果**：
- 基于迭代2的所有功能
- 左侧显示历史对话列表
- 点击可切换到之前的对话
- 关闭浏览器重新打开，对话仍然保留

**不包含**：
- ❌ 文件上传
- ❌ 知识库检索

### 用户故事3: 对话历史持久化

```
作为：高考考生小吾
我想：保存对话、查看历史对话、继续之前的对话
以便：不会丢失对话内容，可以随时回顾

验收条件3.1：用户可以查看和管理历史对话
GIVEN: 用户打开ClarifyChoice前端界面
AND: 用户之前已经与AI进行过对话
WHEN: 用户查看左侧边栏
THEN: 显示历史对话列表

验收条件3.2：用户可以继续之前的对话
GIVEN: 用户在历史对话列表中
WHEN: 用户点击某个历史对话
THEN: 聊天区域加载该对话的完整历史消息

验收条件3.3：对话在关闭浏览器后仍然保留
GIVEN: 用户已进行对话并关闭浏览器
WHEN: 用户重新打开浏览器访问ClarifyChoice
THEN: 之前的对话历史仍然保留并可访问
```

### 实施清单（33个任务）

**数据库设计**
47. 设计SQLite数据库schema（sessions、messages两张表）
48. 在backend安装sqlite3（Python内置）和sqlalchemy
49. 创建backend/database/db.py实现数据库连接和初始化
50. 创建backend/database/models.py定义Session和Message模型

**数据访问层**
51. 在backend/database/crud.py实现create_session函数
52. 实现get_session函数
53. 实现get_sessions函数（获取所有历史对话）
54. 实现save_message函数
55. 实现get_messages函数（获取指定session的消息）
56. 实现delete_session函数

**后端API扩展**
57. 在backend/main.py添加GET /sessions端点（获取历史对话列表）
58. 添加POST /sessions端点（创建新对话）
59. 添加GET /sessions/{session_id}/messages端点（获取指定对话消息）
60. 添加DELETE /sessions/{session_id}端点（删除对话）
61. 修改POST /chat端点保存消息到数据库

**前端历史功能**
62. 创建src/components/chat/Sidebar.tsx显示历史对话列表
63. 创建src/services/sessionApi.ts封装会话管理API
64. 实现新建对话按钮和逻辑
65. 实现切换对话功能（点击历史对话加载消息）
66. 实现删除对话功能（带确认提示）
67. 修改ChatPage集成Sidebar组件
68. 实现会话ID状态管理（使用React Context或Zustand）

**UI优化**
69. 实现响应式布局（侧边栏在移动端可隐藏）
70. 添加加载状态显示
71. 优化空状态显示（无历史对话时）

**测试验证**
72. 测试新建对话功能
73. 测试对话自动保存
74. 测试切换对话后消息正确加载
75. 测试删除对话功能
76. 测试关闭浏览器后重新打开数据保留
77. 跨平台运行验证

**文档**
78. 更新README.md添加迭代3功能说明
79. 创建todo-iteration-3.md记录任务清单

---

## 迭代4：文件上传功能

**功能目标**：用户可以上传成绩单、测评报告等文件

**用户价值**：可以提供个人材料给AI参考

**技术范围**：
- 文件上传UI组件（拖拽区域）
- 文件类型验证（PDF/Word/Excel/PPT/Markdown）
- 文件大小限制（10MB）
- 文件保存到本地文件系统
- 在对话中显示已上传文件列表

**可交付成果**：
- 基于迭代3的所有功能
- 对话界面中有文件上传按钮/区域
- 用户可以拖拽或选择文件上传
- 上传成功后显示文件名和大小
- 文件关联到当前对话session

**不包含**：
- ❌ 文件内容解析（只是上传，AI暂时看不到文件内容）
- ❌ 知识库检索

### 用户故事4: 文件上传功能

```
作为：高考考生小吾
我想：上传成绩单、测评报告等文件
以便：向AI提供我的个人材料作为参考

验收条件4.1：用户可以上传支持的文件类型
GIVEN: 用户在对话界面中
AND: 用户准备了成绩单文件（PDF/Word/Excel/PPT/Markdown格式）
WHEN: 用户点击文件上传按钮或拖拽文件到上传区域
THEN: 系统验证文件类型和大小（≤10MB）后成功上传

验收条件4.2：用户可以查看已上传的文件
GIVEN: 用户已成功上传文件
WHEN: 用户查看对话界面
THEN: 显示已上传文件列表，包含文件名、大小和删除按钮

验收条件4.3：系统拒绝不符合要求的文件
GIVEN: 用户尝试上传文件
WHEN: 文件类型不支持或大小超过10MB
THEN: 系统显示错误提示并拒绝上传
```

### 实施清单（36个任务）

**数据库扩展**
80. 在数据库添加uploaded_files表
81. 在backend/database/models.py添加UploadedFile模型
82. 在backend/database/crud.py添加save_uploaded_file函数
83. 添加get_uploaded_files函数（获取指定session的文件）

**前端上传UI**
84. 创建src/components/chat/FileUpload.tsx组件
85. 实现拖拽上传区域（使用HTML5 drag-and-drop API）
86. 实现文件选择按钮
87. 实现文件类型验证（.pdf/.docx/.xlsx/.pptx/.md）
88. 实现文件大小验证（≤10MB）
89. 显示上传进度（使用XMLHttpRequest或fetch with progress）
90. 显示已上传文件列表（文件名、大小、删除按钮）

**文件上传API**
91. 在backend/main.py添加POST /upload端点处理文件上传
92. 使用FastAPI的UploadFile接收文件
93. 验证文件类型和大小
94. 创建backend/data/uploads/{sessionId}/目录结构
95. 保存文件到本地文件系统
96. 将文件信息保存到数据库
97. 返回上传结果JSON
98. 添加GET /sessions/{session_id}/files端点获取文件列表
99. 添加DELETE /files/{file_id}端点删除文件

**前端集成**
100. 在ChatPage中集成FileUpload组件
101. 创建src/services/fileApi.ts封装文件上传API
102. 实现上传成功后刷新文件列表
103. 实现删除已上传文件功能
104. 在消息中显示"已上传X个文件"提示

**测试验证**
105. 测试拖拽上传功能
106. 测试文件选择上传功能
107. 测试各种文件格式上传
108. 测试文件大小限制
109. 测试非法文件类型拒绝
110. 测试上传进度显示
111. 测试已上传文件列表显示
112. 测试删除文件功能
113. 跨平台运行验证

**文档**
114. 更新README.md添加迭代4功能说明
115. 创建todo-iteration-4.md记录任务清单

---

## 迭代5：知识库RAG集成

**功能目标**：AI可以读取上传文件的内容并基于此回答问题

**用户价值**：AI的回答基于用户提供的具体材料，更加个性化和准确

**技术范围**：
- 文档加载器（支持5种格式）
- 文本分割和向量化
- Chroma向量数据库初始化
- 相似度检索器
- RAG提示词模板
- 将检索结果注入到LLM prompt

**可交付成果**：
- 基于迭代4的所有功能
- 用户上传文件后，文件内容被自动处理
- AI回答时会引用文件中的相关内容
- 可以询问"我上传的成绩单显示什么？"等问题

**不包含**：
- ❌ LangGraph结构化工作流

### 用户故事5: 知识库RAG集成

```
作为：高考考生小吾
我想：AI能够读取我上传文件的内容并基于此回答问题
以便：获得基于我个人材料的个性化和准确的建议

验收条件5.1：AI可以理解上传文件的内容
GIVEN: 用户已上传成绩单文件
AND: 文件已被系统处理并加入知识库
WHEN: 用户询问"我上传的成绩单显示什么？"
THEN: AI回答中包含文件中的具体内容

验收条件5.2：AI基于文件内容提供个性化回答
GIVEN: 用户已上传包含个人信息的文件
AND: 用户提出关于专业推荐的问题
WHEN: AI生成回答
THEN: AI的回答基于用户上传文件中的信息，提供个性化建议
```

### 实施清单（46个任务）

**依赖安装**
116. 在backend安装文档处理库（pypdf2、python-docx、openpyxl、python-pptx）
117. 安装向量数据库（chromadb）
118. 安装embedding模型依赖

**文档加载器实现**
119. 创建backend/knowledge/loader.py
120. 实现load_pdf函数（使用pypdf2）
121. 实现load_docx函数（使用python-docx）
122. 实现load_xlsx函数（使用openpyxl，转换为文本）
123. 实现load_pptx函数（使用python-pptx）
124. 实现load_markdown函数（直接读取）
125. 实现统一的load_document函数（根据文件类型分发）

**文本处理**
126. 创建backend/knowledge/text_processor.py
127. 实现文本分割函数（chunk_size=1000, overlap=200）
128. 实现文本清洗函数（去除特殊字符、多余空格）

**向量数据库**
129. 创建backend/knowledge/vectorstore.py
130. 实现初始化Chroma数据库函数
131. 实现添加文档到向量库函数
132. 实现相似度检索函数（k=5）
133. 配置embedding模型（如OpenAI embeddings或本地模型）
134. 实现session级别的collection管理

**文件处理API**
135. 在backend/main.py添加POST /process-file端点
136. 接收文件路径和session_id
137. 调用文档加载器解析文件
138. 对文本进行分割
139. 将文档chunks添加到向量数据库
140. 返回处理结果

**前端调用**
141. 修改src/services/fileApi.ts在文件上传成功后自动调用/process-file
142. 处理文件处理的异步状态
143. 显示"正在处理文件..."的加载提示
144. 处理完成后提示用户"文件已加入知识库"

**RAG实现**
145. 修改backend/main.py的/chat端点集成检索逻辑
146. 在接收消息后先进行向量检索
147. 将检索结果格式化为上下文
148. 将上下文注入到LLM的prompt中
149. 调整prompt模板以更好利用检索内容

**测试验证**
150. 测试上传PDF后文件内容被正确解析
151. 测试上传Word文档解析
152. 测试上传Excel文档解析
153. 测试上传PPT文档解析
154. 测试上传Markdown文档解析
155. 测试向量检索返回相关内容
156. 测试AI回答中包含文件内容
157. 测试询问"我上传的文件说了什么"类问题
158. 测试多个文件上传后的综合检索
159. 跨平台运行验证

**文档**
160. 更新README.md添加迭代5功能说明
161. 创建todo-iteration-5.md记录任务清单

---

## 迭代6：LangGraph智能体工作流

**功能目标**：结构化的专业推荐流程，生成Markdown格式的推荐报告

**用户价值**：获得结构化、逻辑清晰的专业推荐报告

**技术范围**：
- 定义LangGraph State结构
- 创建多节点工作流：
  - 意图识别节点
  - 信息收集节点
  - 知识检索节点
  - 专业匹配节点
  - 报告生成节点
- 配置节点间的路由逻辑
- Markdown报告模板

**可交付成果**：
- 基于迭代5的所有功能
- AI会主动引导对话流程（"先了解你的成绩"→"兴趣爱好"→"生成推荐"）
- 最终生成一份完整的Markdown格式推荐报告
- 报告包含：推荐专业、院校选择、理由分析等

### 用户故事6: LangGraph智能体工作流

```
作为：高考考生小吾
我想：获得结构化的专业推荐流程和Markdown格式的推荐报告
以便：得到逻辑清晰、格式规范的专业推荐结果

验收条件6.1：AI主动引导对话流程
GIVEN: 用户开始新的专业推荐对话
WHEN: 用户表达想要获得专业推荐的意图
THEN: AI主动询问用户的高考成绩、兴趣爱好、职业偏好等信息

验收条件6.2：AI生成结构化的推荐报告
GIVEN: 用户已提供完整的个人信息
AND: 用户请求生成推荐报告或AI判断信息收集完成
WHEN: AI执行推荐报告生成流程
THEN: AI生成Markdown格式的报告，包含推荐专业、核心课程、匹配理由、未来职业方向、就业前景与挑战、国内录取分数排名前5的大学及专业名称、给小吾的建议

验收条件6.3：报告处于RESEARCH/INNOVATE/PLAN/EXECUTE/REVIEW模式
GIVEN: AI在生成推荐报告过程中
WHEN: AI处于不同的工作阶段
THEN: AI明确标识当前所处的模式（RESEARCH/INNOVATE/PLAN/EXECUTE/REVIEW），并按照相应模式的规则与用户交互
```

### 实施清单（43个任务）

**依赖安装**
162. 确认langgraph已安装（应在之前已安装）

**State设计**
163. 创建backend/agents/state.py定义State类
164. 定义字段：user_input、chat_history、user_info、retrieved_docs、recommendations、report

**节点实现**
165. 创建backend/agents/nodes.py
166. 实现intent_recognition节点（识别用户意图：提供信息/询问问题/请求推荐）
167. 实现info_collection节点（收集用户成绩、兴趣、地域偏好等）
168. 实现knowledge_retrieval节点（从向量库检索相关专业信息）
169. 实现major_matching节点（根据用户信息匹配合适专业）
170. 实现report_generation节点（生成Markdown格式推荐报告）

**工作流定义**
171. 创建backend/agents/workflow.py
172. 定义StateGraph
173. 添加所有节点到图
174. 定义条件边（根据意图路由到不同节点）
175. 定义普通边（节点间的顺序连接）
176. 设置入口节点和结束条件
177. 编译工作流

**集成到主服务**
178. 修改backend/main.py的/chat端点使用LangGraph工作流
179. 将用户消息传入工作流State
180. 执行工作流并获取输出
181. 保持流式输出能力（使用LangGraph的streaming）

**报告模板**
182. 创建backend/templates/report_template.py
183. 定义Markdown报告结构（标题、个人情况、推荐专业、院校选择、理由分析）
184. 实现报告生成函数

**前端优化**
185. 安装react-markdown和相关依赖（npm install react-markdown remark-gfm）
186. 优化MessageList对Markdown的渲染（使用react-markdown）
187. 添加代码高亮支持（安装react-syntax-highlighter）
188. 添加表格渲染支持（配置remark-gfm）
189. 优化长报告的显示（实现折叠/展开功能）

**引导式对话**
190. 实现AI主动提问机制（"请告诉我你的高考分数"）
191. 实现信息确认环节（"确认你的信息：分数XXX，兴趣XXX"）
192. 实现报告生成触发（用户说"生成推荐"或收集完信息后自动触发）

**测试验证**
193. 测试完整对话流程（从打招呼到生成报告）
194. 测试AI能识别不同意图
195. 测试信息收集过程的完整性
196. 测试知识检索集成到推荐中
197. 测试报告格式正确性
198. 测试报告内容相关性和准确性
199. 测试中断后重新开始的处理
200. 跨平台运行验证

**文档**
201. 更新README.md添加迭代6功能说明
202. 创建todo-iteration-6.md记录任务清单
203. 编写完整的用户使用指南
204. 编写开发者文档说明架构和扩展方法

---

## 迭代总览（204个任务）

### 迭代1：基础对话系统（29个任务）
**交付价值**：用户可以与AI对话，验证基本可行性

### 迭代2：流式输出体验（17个任务）
**交付价值**：AI回复实时逐字显示，体验升级

### 迭代3：对话历史持久化（33个任务）
**交付价值**：对话永久保存，可以查看历史

### 迭代4：文件上传功能（36个任务）
**交付价值**：可以上传成绩单等文件

### 迭代5：知识库RAG集成（46个任务）
**交付价值**：AI基于上传文件内容回答

### 迭代6：LangGraph工作流（43个任务）
**交付价值**：结构化专业推荐报告

---

## 关键特性

### 1. 独立可交付
每个迭代完成后：
- ✅ 项目可以运行
- ✅ 功能完整可用
- ✅ 可以演示给用户
- ✅ 有明确的用户价值

### 2. 渐进增强
```
迭代1 → 基础对话（能用）
迭代2 → + 流式输出（更好用）
迭代3 → + 历史保存（不丢失）
迭代4 → + 文件上传（可提供材料）
迭代5 → + 知识库（AI能读文件）
迭代6 → + 工作流（专业报告）
```

### 3. 风险可控
- 如果1个月不够，至少有迭代1-3可用
- 如果某个迭代困难，可以暂时跳过
- 每个迭代都是检验点

### 4. AI友好
- 每个迭代目标明确，易于AI理解
- 任务粒度适中，适合AI辅助开发
- 可以对每个迭代单独寻求AI帮助
