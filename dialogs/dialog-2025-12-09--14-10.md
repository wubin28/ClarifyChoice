## Me:

```markdown
我喜欢“方案A：基于Vercel AI SDK + Next.js自建前端” ENTER PLAN MODE
```

## Claude app with sonnet 4.5:

```markdown
[MODE: PLAN]

很好！既然你选择了方案A，我现在为你制定详细的实施计划。

## 项目目标

构建基于Vercel AI SDK + Next.js 14 + LangChain v1.0 + LangGraph的"高考志愿专业推荐"智能体，支持：
- AI流式对话
- 文件上传（PDF/Word/Excel/PPT/Markdown）
- 对话历史保存
- 多轮对话上下文管理

## 技术栈规格

**前端**：
- Next.js 14.x（App Router）
- Vercel AI SDK 3.x
- React 18.x
- Tailwind CSS 3.x
- TypeScript

**后端（Next.js API Routes）**：
- LangChain 0.3.x（Python）
- LangGraph
- FastAPI（作为LangChain服务）
- 向量数据库（Chroma/FAISS）

**本地存储**：
- SQLite（对话历史）
- 文件系统（上传文件）

**流式通信**：
- Server-Sent Events (SSE)
- Vercel AI SDK StreamingTextResponse

## 详细实施规格

### 阶段1：环境准备

**1.1 开发环境验证**
- 确认Node.js 18+已安装（macOS/Windows WSL2）
- 确认Python 3.10+已安装
- 确认pnpm/npm/yarn包管理器可用

**1.2 创建项目目录结构**
```
ClarifyChoice/
├── frontend/          # Next.js应用
├── backend/           # LangChain/LangGraph服务
├── knowledge-base/    # 知识库文件存储
└── data/             # SQLite数据库和上传文件
```

### 阶段2：Next.js前端初始化

**2.1 创建Next.js项目**
- 使用`npx create-next-app@latest`初始化
- 选择：TypeScript、ESLint、Tailwind CSS、App Router、src目录

**2.2 安装核心依赖**
```json
{
  "ai": "^3.4.0",
  "react": "^18.3.0",
  "next": "^14.2.0"
}
```

**2.3 项目文件结构设计**
```
frontend/
├── app/
│   ├── api/
│   │   ├── chat/
│   │   │   └── route.ts          # 聊天API端点
│   │   └── upload/
│   │       └── route.ts          # 文件上传端点
│   ├── layout.tsx
│   └── page.tsx                  # 主聊天界面
├── components/
│   ├── chat/
│   │   ├── ChatInterface.tsx    # 主对话组件
│   │   ├── MessageList.tsx      # 消息列表
│   │   ├── MessageInput.tsx     # 输入框
│   │   └── FileUpload.tsx       # 文件上传组件
│   └── ui/
│       └── ...                   # UI基础组件
└── lib/
    ├── chat-history.ts           # 对话历史管理
    └── types.ts                  # TypeScript类型定义
```

### 阶段3：后端LangChain服务搭建

**3.1 创建Python虚拟环境**
- 在backend目录创建venv
- 安装依赖：langchain、langgraph、fastapi、uvicorn

**3.2 LangChain服务架构设计**
```python
backend/
├── main.py                      # FastAPI入口
├── agents/
│   └── advisor_agent.py         # LangGraph智能体定义
├── knowledge/
│   ├── loader.py                # 文档加载器
│   ├── vectorstore.py           # 向量数据库管理
│   └── retriever.py             # 检索器
├── models/
│   └── llm_config.py            # LLM配置
└── utils/
    ├── file_processor.py        # 文件处理工具
    └── stream_handler.py        # 流式输出处理
```

**3.3 实现LangGraph工作流**
- 定义State结构（用户输入、对话历史、检索结果）
- 创建节点：意图识别 → 知识检索 → 专业推荐 → 报告生成
- 配置边和条件路由

**3.4 知识库初始化**
- 实现多格式文档加载器（PDF/Word/Excel/PPT/Markdown）
- 配置文本分割策略（chunk_size=1000, overlap=200）
- 初始化向量数据库（Chroma推荐，本地存储）
- 创建检索器（similarity_search, k=5）

### 阶段4：前端UI组件开发

**4.1 ChatInterface主组件**
- 使用Vercel AI SDK的`useChat` hook
- 配置API端点：`/api/chat`
- 实现消息渲染逻辑（用户消息、AI消息、系统消息）

**4.2 MessageList组件**
- 实现自动滚动到最新消息
- 支持Markdown渲染（使用react-markdown）
- 区分消息类型样式（user/assistant/system）

**4.3 MessageInput组件**
- 文本输入框（支持多行、Enter发送）
- 发送按钮（带加载状态）
- 文件上传触发按钮

**4.4 FileUpload组件**
- 拖拽上传区域
- 文件类型验证（PDF/DOCX/XLSX/PPTX/MD）
- 文件大小限制（10MB）
- 上传进度显示
- 已上传文件列表展示

**4.5 对话历史侧边栏（可选）**
- 历史对话列表
- 新建对话按钮
- 删除对话功能

### 阶段5：后端API Routes实现

**5.1 实现 /api/chat/route.ts**

**核心逻辑**：
```typescript
// 伪代码结构
export async POST(req: Request) {
  // 1. 解析请求（messages, sessionId）
  // 2. 调用后端LangChain服务
  // 3. 使用streamText处理响应
  // 4. 返回StreamingTextResponse
}
```

**具体步骤**：
- 接收前端消息数组
- 提取sessionId（用于对话历史）
- 构造POST请求到FastAPI服务（http://localhost:8000/chat）
- 处理流式响应（使用AI SDK的streamText）
- 错误处理和重试逻辑

**5.2 实现 /api/upload/route.ts**

**功能**：
- 接收FormData文件
- 验证文件类型和大小
- 保存到data/uploads/{sessionId}/目录
- 调用后端处理接口，将文件加入知识库
- 返回上传结果JSON

**5.3 桥接Next.js与FastAPI**

**通信方式**：
- Next.js API Route → HTTP POST → FastAPI
- FastAPI返回流式JSON → Next.js转发SSE → 前端

**数据格式**：
```json
{
  "messages": [...],
  "sessionId": "uuid",
  "uploadedFiles": ["file1.pdf"]
}
```

### 阶段6：LangChain流式输出配置

**6.1 FastAPI流式端点**
```python
@app.post("/chat")
async def chat_stream(request: ChatRequest):
    # 返回StreamingResponse
    # 使用LangChain的streaming callbacks
```

**6.2 LangGraph streaming配置**
- 启用streaming=True
- 配置StreamingStdOutCallbackHandler
- 实现token级别的流式输出

**6.3 前端集成验证**
- 验证useChat自动处理SSE流
- 确认逐字显示效果

### 阶段7：对话历史持久化

**7.1 数据库设计**

**sessions表**：
```sql
CREATE TABLE sessions (
  id TEXT PRIMARY KEY,
  created_at TIMESTAMP,
  updated_at TIMESTAMP,
  title TEXT
);
```

**messages表**：
```sql
CREATE TABLE messages (
  id INTEGER PRIMARY KEY,
  session_id TEXT,
  role TEXT,
  content TEXT,
  created_at TIMESTAMP,
  FOREIGN KEY(session_id) REFERENCES sessions(id)
);
```

**uploaded_files表**：
```sql
CREATE TABLE uploaded_files (
  id INTEGER PRIMARY KEY,
  session_id TEXT,
  filename TEXT,
  filepath TEXT,
  uploaded_at TIMESTAMP
);
```

**7.2 实现数据访问层**
- lib/db.ts：SQLite连接管理（使用better-sqlite3）
- lib/chat-history.ts：CRUD操作封装

**7.3 集成到API Routes**
- 每次对话保存到数据库
- 前端加载时从数据库读取历史

### 阶段8：多轮对话上下文管理

**8.1 前端实现**
- useChat自动管理messages数组
- 每次请求携带完整对话历史

**8.2 后端实现**
- LangGraph State包含chat_history字段
- 检索时考虑上下文（最近3轮对话）
- 报告生成时综合全部对话

**8.3 上下文窗口管理**
- 限制发送的历史消息数量（最近10轮）
- 超长对话时实现摘要机制

### 阶段9：知识库文件处理

**9.1 文档加载器实现**

**支持格式**：
- PDF：PyPDF2或pdfplumber
- Word：python-docx
- Excel：openpyxl + 转换为文本
- PPT：python-pptx
- Markdown：直接读取

**9.2 文件处理流程**
- 用户上传 → 保存到文件系统
- 后端接收上传通知 → 解析文件内容
- 文本分割 → 向量化 → 存入向量数据库
- 关联到当前session

**9.3 动态知识库更新**
- 支持单个对话session的独立知识库
- 合并全局知识库 + session知识库检索

### 阶段10：启动脚本编写

**10.1 后端启动脚本**

**backend/start.sh（macOS/Linux）**：
```bash
#!/bin/bash
source venv/bin/activate
uvicorn main:app --reload --port 8000
```

**backend/start.ps1（Windows PowerShell）**：
```powershell
.\venv\Scripts\Activate.ps1
uvicorn main:app --reload --port 8000
```

**10.2 前端启动脚本**

**frontend/start.sh**：
```bash
#!/bin/bash
pnpm install
pnpm dev
```

**10.3 一键启动脚本（根目录）**

**start-all.sh**：
```bash
#!/bin/bash
# 启动后端
cd backend && ./start.sh &
# 等待后端启动
sleep 3
# 启动前端
cd ../frontend && pnpm dev
```

### 阶段11：测试验证

**11.1 单元测试项**
- 文件上传功能测试
- API端点响应测试
- 数据库CRUD测试
- 文档加载器测试

**11.2 集成测试项**
- 端到端对话流程
- 文件上传后知识检索
- 多轮对话上下文连贯性
- 流式输出完整性

**11.3 跨平台测试**
- macOS环境运行验证
- Windows WSL2环境运行验证
- 端口占用检查

### 阶段12：文档编写

**12.1 README.md**
- 项目介绍
- 技术栈说明
- 快速开始指南
- 目录结构说明

**12.2 开发文档**
- 环境配置详细步骤
- 依赖安装命令
- 常见问题解决

**12.3 API文档**
- FastAPI自动生成文档（/docs）
- Next.js API Routes说明

**12.4 部署文档**
- 本地部署步骤
- 配置文件说明
- 故障排查指南

---

## 实施清单

1. 验证macOS和Windows WSL2上Node.js 18+和Python 3.10+已安装
2. 创建项目根目录ClarifyChoice及子目录frontend、backend、knowledge-base、data
3. 在frontend目录执行npx create-next-app@latest初始化Next.js项目（选择TypeScript、Tailwind、App Router）
4. 在frontend目录安装Vercel AI SDK和相关依赖（ai、react、next）
5. 创建frontend目录下的文件结构（app/api/chat、app/api/upload、components、lib）
6. 在backend目录创建Python虚拟环境并激活
7. 在backend虚拟环境安装LangChain、LangGraph、FastAPI、uvicorn等依赖
8. 创建backend目录下的文件结构（main.py、agents、knowledge、models、utils）
9. 编写backend/main.py作为FastAPI应用入口
10. 实现backend/agents/advisor_agent.py定义LangGraph智能体State和工作流节点
11. 配置LangGraph工作流的边和条件路由
12. 实现backend/knowledge/loader.py支持PDF、Word、Excel、PPT、Markdown文件加载
13. 实现backend/knowledge/vectorstore.py初始化Chroma向量数据库
14. 实现backend/knowledge/retriever.py配置相似度检索器（k=5）
15. 实现backend/utils/file_processor.py处理文件解析和文本分割（chunk_size=1000, overlap=200）
16. 实现backend/utils/stream_handler.py配置LangChain流式回调处理器
17. 在backend/main.py创建POST /chat端点返回StreamingResponse
18. 编写frontend/components/chat/ChatInterface.tsx使用useChat hook
19. 编写frontend/components/chat/MessageList.tsx实现消息列表和Markdown渲染
20. 编写frontend/components/chat/MessageInput.tsx实现输入框和发送功能
21. 编写frontend/components/chat/FileUpload.tsx实现拖拽上传和文件验证
22. 编写frontend/app/api/chat/route.ts实现POST方法调用FastAPI服务
23. 在frontend/app/api/chat/route.ts中使用streamText处理流式响应并返回StreamingTextResponse
24. 编写frontend/app/api/upload/route.ts实现文件接收、验证和保存
25. 在frontend/app/api/upload/route.ts中调用backend文件处理接口更新知识库
26. 编写frontend/app/page.tsx集成ChatInterface组件作为主界面
27. 设计SQLite数据库schema（sessions、messages、uploaded_files三张表）
28. 在frontend/lib/db.ts实现SQLite连接管理（使用better-sqlite3）
29. 在frontend/lib/chat-history.ts实现对话历史CRUD操作
30. 在frontend/app/api/chat/route.ts中集成对话历史保存逻辑
31. 在frontend ChatInterface组件加载时从数据库读取历史对话
32. 配置useChat自动管理messages数组实现多轮对话
33. 在backend LangGraph State中添加chat_history字段
34. 实现backend检索时结合最近3轮对话上下文
35. 实现frontend限制发送历史消息数量为最近10轮
36. 实现backend文件上传后的动态知识库更新逻辑
37. 配置session级别独立知识库与全局知识库合并检索
38. 编写backend/start.sh脚本（macOS/Linux）启动FastAPI服务
39. 编写backend/start.ps1脚本（Windows PowerShell）启动FastAPI服务
40. 编写frontend/start.sh脚本启动Next.js开发服务器
41. 编写根目录start-all.sh一键启动前后端服务
42. 测试文件上传功能（验证各格式文件上传和大小限制）
43. 测试API端点响应（/api/chat和/api/upload）
44. 测试数据库CRUD操作（创建、读取、更新、删除对话）
45. 测试文档加载器处理各类文件格式
46. 执行端到端对话流程测试
47. 测试文件上传后知识检索准确性
48. 测试多轮对话上下文连贯性
49. 验证流式输出完整性和逐字显示效果
50. 在macOS环境运行完整项目验证
51. 在Windows WSL2环境运行完整项目验证
52. 检查端口占用情况（8000和3000）
53. 编写README.md包含项目介绍、技术栈、快速开始指南
54. 编写开发文档详细说明环境配置和依赖安装
55. 验证FastAPI自动生成的API文档（访问http://localhost:8000/docs）
56. 编写部署文档说明本地部署步骤和故障排查
57. 创建data目录下的uploads和database子目录
58. 在根目录创建todo-2025-12-09--XX-XX.md文件记录本实施清单
59. 在todo文件末尾添加审查部分总结实施要点

---

现在我将创建时间戳的todo文件来记录这个实施清单。

完成！我已经创建了详细的实施计划和todo文件。

## 计划总结

这个计划包含了**59个具体实施步骤**，涵盖：

✅ **环境准备**（2步）  
✅ **Next.js前端初始化**（3步）  
✅ **后端LangChain服务搭建**（4步）  
✅ **LangGraph智能体实现**（2步）  
✅ **知识库系统**（4步）  
✅ **流式输出配置**（2步）  
✅ **前端UI组件**（4步）  
✅ **API Routes实现**（5步）  
✅ **对话历史持久化**（5步）  
✅ **多轮对话上下文管理**（4步）  
✅ **知识库文件处理**（2步）  
✅ **启动脚本**（4步）  
✅ **测试验证**（11步）  
✅ **文档编写**（4步）  
✅ **收尾工作**（3步）

## 计划特点

1. **AI可执行性强**：每个步骤都足够具体，可以直接交给AI助手执行
2. **技术规格明确**：指定了确切的版本号、配置参数、文件路径
3. **无需创造性决策**：实施过程中不需要做技术选型或架构决策
4. **跨平台兼容**：考虑了macOS和Windows WSL2两个环境
5. **测试覆盖完整**：包含单元测试、集成测试、跨平台测试

## todo文件位置

📄 **文件路径**：`/home/claude/todo-2025-12-09--15-30.md`

这个文件包含：
- 完整的59步实施清单（带复选框）
- 详细的项目目录结构
- 关键技术要点说明
- 审查部分（总结实施要点和潜在风险）

---

**下一步推荐操作**：

1. **进入下一模式的指令**：`ENTER EXECUTE MODE`

2. **继续停留在本模式讨论**：可将以下内容复制粘贴给我：
   `我不希望你为人类制定工作计划。我希望看到你为自己这位AI制定工作计划，只列出工作项清单即可，无须预估每个工作项的时长。请基于这一点，将计划转换为带编号的顺序清单，每个操作作为单独项目，然后创建时间戳文件，重新执行 PLAN 模式。`

   **或者**，如果你对计划有任何疑问或需要调整，可以直接告诉我：
   - 哪些步骤需要更详细的说明？
   - 是否需要调整实施顺序？
   - 是否有遗漏的关键步骤？
```